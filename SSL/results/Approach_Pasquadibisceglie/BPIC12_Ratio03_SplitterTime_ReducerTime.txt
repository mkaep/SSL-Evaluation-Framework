Training File: dataset/inp_log_train_red_001.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 001
 Test File: dataset/inp_log_test.csv
              precision    recall  f1-score   support

           0    0.00000   0.00000   0.00000        40
           1    0.00000   0.00000   0.00000        46
           2    0.02941   0.02500   0.02703        40
           3    0.00000   0.00000   0.00000       146
           4    0.00000   0.00000   0.00000         3
           5    0.00915   0.15789   0.01729        38
           6    0.00000   0.00000   0.00000        39
           7    0.50000   0.00870   0.01709       115
           8    0.00000   0.00000   0.00000        34
           9    0.00000   0.00000   0.00000        18
          10    0.00000   0.00000   0.00000        26
          11    0.00000   0.00000   0.00000        16
          12    0.00000   0.00000   0.00000        25
          13    0.00000   0.00000   0.00000        11
          14    0.33333   0.03333   0.06061        30
          15    0.00000   0.00000   0.00000        11
          16    0.00000   0.00000   0.00000        46
          17    0.00000   0.00000   0.00000       144
          18    0.00000   0.00000   0.00000        37
          19    0.75000   0.02459   0.04762       122
          20    0.00000   0.00000   0.00000         6
          21    0.00000   0.00000   0.00000        16
          22    0.00000   0.00000   0.00000         4
          23    0.00000   0.00000   0.00000        50
          24    0.00000   0.00000   0.00000        34
          25    0.00000   0.00000   0.00000         6
          26    0.00000   0.00000   0.00000        24
          27    0.07018   1.00000   0.13115        32
          28    0.00000   0.00000   0.00000        50
          29    0.00000   0.00000   0.00000        11
          30    0.00000   0.00000   0.00000        40
          31    0.00000   0.00000   0.00000        11
          32    0.00000   0.00000   0.00000        39

    accuracy                        0.03359      1310
   macro avg    0.05127   0.03786   0.00911      1310
weighted avg    0.12425   0.03359   0.01185      1310

Accuracy on test data: 0.025444405153393745
Loss on test data: 3.3168558753629562              precision    recall  f1-score   support

           0    1.00000   0.00069   0.00137      1455
           1    0.00000   0.00000   0.00000      1524
           2    0.01250   0.00825   0.00994      1455
           3    0.00000   0.00000   0.00000      5057
           4    0.00000   0.00000   0.00000       157
           5    0.00935   0.11892   0.01734      1665
           6    0.00000   0.00000   0.00000      1586
           7    0.38095   0.00216   0.00430      3696
           8    0.00000   0.00000   0.00000      1120
           9    0.00000   0.00000   0.00000       422
          10    0.00000   0.00000   0.00000       590
          11    0.00000   0.00000   0.00000       707
          12    0.00000   0.00000   0.00000      1105
          13    0.00000   0.00000   0.00000       408
          14    0.06198   0.01461   0.02364      1027
          15    0.00000   0.00000   0.00000       408
          16    0.00000   0.00000   0.00000      1522
          17    0.00000   0.00000   0.00000      5023
          18    0.20000   0.00073   0.00145      1373
          19    0.80000   0.00107   0.00214      3740
          20    0.00000   0.00000   0.00000        62
          21    0.00000   0.00000   0.00000       519
          22    0.00000   0.00000   0.00000        24
          23    0.33333   0.00047   0.00095      2108
          24    0.00000   0.00000   0.00000      1120
          25    0.00000   0.00000   0.00000        62
          26    0.00000   0.00000   0.00000      1081
          27    0.05151   1.00000   0.09798       924
          28    0.57143   0.00190   0.00378      2107
          29    0.00000   0.00000   0.00000       408
          30    0.00000   0.00000   0.00000      1455
          31    0.00000   0.00000   0.00000       408
          32    0.00000   0.00000   0.00000      1586

    accuracy                        0.02544     45904
   macro avg    0.10367   0.03481   0.00494     45904
weighted avg    0.17823   0.02544   0.00427     45904

------------------------------------------
Training File: dataset/inp_log_train_red_005.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 005
 Test File: dataset/inp_log_test.csv
              precision    recall  f1-score   support

           0    0.00000   0.00000   0.00000       166
           1    0.00000   0.00000   0.00000       185
           2    0.00000   0.00000   0.00000       166
           3    0.00000   0.00000   0.00000       515
           4    1.00000   0.05000   0.09524        20
           5    0.00995   0.15888   0.01873       214
           6    0.00000   0.00000   0.00000       169
           7    0.53608   0.10297   0.17276       505
           8    0.00000   0.00000   0.00000       139
           9    0.23404   0.15068   0.18333        73
          10    0.00000   0.00000   0.00000        98
          11    0.00000   0.00000   0.00000        69
          12    0.00000   0.00000   0.00000       116
          13    0.00000   0.00000   0.00000        46
          14    0.20000   0.02752   0.04839       109
          15    0.25000   0.02174   0.04000        46
          16    0.00000   0.00000   0.00000       185
          17    0.00000   0.00000   0.00000       505
          18    0.00000   0.00000   0.00000       155
          19    0.81250   0.02457   0.04771       529
          20    0.00000   0.00000   0.00000         9
          21    0.00000   0.00000   0.00000        52
          22    0.00000   0.00000   0.00000         6
          23    0.38983   0.11735   0.18039       196
          24    0.00000   0.00000   0.00000       139
          25    0.00000   0.00000   0.00000         9
          26    0.00000   0.00000   0.00000       114
          27    0.07374   1.00000   0.13736       116
          28    0.00000   0.00000   0.00000       196
          29    1.00000   0.02174   0.04255        46
          30    0.00000   0.00000   0.00000       166
          31    0.00000   0.00000   0.00000        46
          32    0.00000   0.00000   0.00000       169

    accuracy                        0.04835      5274
   macro avg    0.13655   0.05077   0.02929      5274
weighted avg    0.17141   0.04835   0.03643      5274

Accuracy on test data: 0.03141338378190994
Loss on test data: 3.4028088140670496              precision    recall  f1-score   support

           0    0.00000   0.00000   0.00000      1455
           1    0.00000   0.00000   0.00000      1524
           2    0.00000   0.00000   0.00000      1455
           3    1.00000   0.00020   0.00040      5057
           4    0.00000   0.00000   0.00000       157
           5    0.00929   0.17297   0.01764      1665
           6    0.00000   0.00000   0.00000      1586
           7    0.35809   0.03653   0.06629      3696
           8    0.00000   0.00000   0.00000      1120
           9    0.18605   0.03791   0.06299       422
          10    0.00000   0.00000   0.00000       590
          11    0.00000   0.00000   0.00000       707
          12    0.00000   0.00000   0.00000      1105
          13    0.00000   0.00000   0.00000       408
          14    0.07143   0.00195   0.00379      1027
          15    0.00000   0.00000   0.00000       408
          16    0.00000   0.00000   0.00000      1522
          17    1.00000   0.00040   0.00080      5023
          18    0.00000   0.00000   0.00000      1373
          19    0.67347   0.00882   0.01742      3740
          20    0.00000   0.00000   0.00000        62
          21    0.00000   0.00000   0.00000       519
          22    0.00000   0.00000   0.00000        24
          23    0.35043   0.01945   0.03685      2108
          24    0.00000   0.00000   0.00000      1120
          25    0.00000   0.00000   0.00000        62
          26    0.00000   0.00000   0.00000      1081
          27    0.06633   1.00000   0.12441       924
          28    0.00000   0.00000   0.00000      2107
          29    0.00000   0.00000   0.00000       408
          30    0.00000   0.00000   0.00000      1455
          31    0.00000   0.00000   0.00000       408
          32    0.00000   0.00000   0.00000      1586

    accuracy                        0.03141     45904
   macro avg    0.11258   0.03873   0.01002     45904
weighted avg    0.32436   0.03141   0.01239     45904

------------------------------------------
Training File: dataset/inp_log_train_red_01.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 01
 Test File: dataset/inp_log_test.csv
              precision    recall  f1-score   support

           0    0.98827   0.96839   0.97823       348
           1    0.47022   0.93687   0.62616       396
           2    0.70833   0.58621   0.64151       348
           3    0.73706   0.87948   0.80200      1004
           4    0.88889   0.66667   0.76190        36
           5    0.75000   0.08845   0.15824       407
           6    0.73333   0.30899   0.43478       356
           7    0.86862   0.95317   0.90893      1089
           8    0.48073   0.86813   0.61880       273
           9    0.38247   0.64430   0.48000       149
          10    0.95604   0.43939   0.60208       198
          11    1.00000   0.01852   0.03636       162
          12    0.00000   0.00000   0.00000       248
          13    0.72581   0.41667   0.52941       108
          14    0.97561   0.33333   0.49689       240
          15    0.84000   0.19444   0.31579       108
          16    1.00000   0.05556   0.10526       396
          17    0.99693   0.99286   0.99489       980
          18    1.00000   0.97256   0.98609       328
          19    0.80058   0.97345   0.87859      1130
          20    1.00000   0.25000   0.40000        16
          21    0.64789   0.41441   0.50549       111
          22    0.66667   0.20000   0.30769        10
          23    0.78139   0.76321   0.77219       473
          24    0.97817   0.82051   0.89243       273
          25    1.00000   0.06250   0.11765        16
          26    0.74297   0.75510   0.74899       245
          27    0.32239   0.99083   0.48649       218
          28    0.49196   0.97040   0.65292       473
          29    0.88889   0.44444   0.59259       108
          30    0.99703   0.96552   0.98102       348
          31    0.75510   0.34259   0.47134       108
          32    0.46388   0.34270   0.39418       356

    accuracy                        0.72583     11059
   macro avg    0.75876   0.56423   0.56603     11059
weighted avg    0.77142   0.72583   0.69027     11059

Accuracy on test data: 0.6444754004478455
Loss on test data: 1.5792570565896984              precision    recall  f1-score   support

           0    0.97538   0.92577   0.94993      1455
           1    0.31340   0.80118   0.45055      1524
           2    0.62849   0.57320   0.59957      1455
           3    0.74887   0.84853   0.79559      5057
           4    0.62745   0.20382   0.30769       157
           5    0.32121   0.03183   0.05792      1665
           6    0.70698   0.26166   0.38196      1586
           7    0.77520   0.90314   0.83429      3696
           8    0.44337   0.85982   0.58505      1120
           9    0.06903   0.16588   0.09749       422
          10    0.69281   0.17966   0.28533       590
          11    0.00000   0.00000   0.00000       707
          12    0.00000   0.00000   0.00000      1105
          13    0.06494   0.02451   0.03559       408
          14    0.27419   0.01655   0.03122      1027
          15    0.06000   0.00735   0.01310       408
          16    0.77778   0.02300   0.04467      1522
          17    0.99333   0.97910   0.98616      5023
          18    0.99546   0.95776   0.97624      1373
          19    0.73528   0.95508   0.83089      3740
          20    0.60000   0.04839   0.08955        62
          21    0.34173   0.18304   0.23839       519
          22    0.00000   0.00000   0.00000        24
          23    0.45760   0.35579   0.40032      2108
          24    0.97679   0.82679   0.89555      1120
          25    0.00000   0.00000   0.00000        62
          26    0.73313   0.68363   0.70752      1081
          27    0.31869   0.98918   0.48207       924
          28    0.42802   0.83531   0.56601      2107
          29    0.09574   0.04412   0.06040       408
          30    0.97206   0.93265   0.95195      1455
          31    0.07031   0.02206   0.03358       408
          32    0.42613   0.29823   0.35089      1586

    accuracy                        0.64448     45904
   macro avg    0.47344   0.42233   0.39514     45904
weighted avg    0.63600   0.64448   0.60003     45904

------------------------------------------
Training File: dataset/inp_log_train_red_02.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 02
 Test File: dataset/inp_log_test.csv
              precision    recall  f1-score   support

           0    0.98618   0.98466   0.98542       652
           1    0.80508   0.85696   0.83021       776
           2    0.72848   0.67485   0.70064       652
           3    0.81122   0.78986   0.80040      2051
           4    0.92308   0.62338   0.74419        77
           5    0.42693   0.36165   0.39159       824
           6    0.70206   0.34000   0.45813       700
           7    0.87724   0.96835   0.92055      2022
           8    0.54839   0.85884   0.66937       673
           9    0.94286   0.44147   0.60137       299
          10    0.88546   0.55989   0.68601       359
          11    0.42974   0.81677   0.56317       322
          12    0.36377   0.51288   0.42565       466
          13    0.88393   0.47826   0.62069       207
          14    0.72000   0.58696   0.64671       460
          15    0.79167   0.55072   0.64957       207
          16    0.75092   0.78764   0.76884       777
          17    0.99797   0.98795   0.99294      1992
          18    0.99836   0.99021   0.99427       613
          19    0.89479   0.83988   0.86647      2086
          20    0.90000   0.37500   0.52941        24
          21    0.80928   0.77340   0.79093       203
          22    0.75000   0.21429   0.33333        14
          23    0.86251   0.79869   0.82938       919
          24    0.94664   0.81724   0.87719       673
          25    1.00000   0.12500   0.22222        24
          26    0.78378   0.75983   0.77162       458
          27    0.39432   0.99623   0.56501       530
          28    0.78881   0.95103   0.86236       919
          29    0.50000   0.79227   0.61308       207
          30    0.98915   0.97853   0.98381       652
          31    0.70000   0.54106   0.61035       207
          32    0.40000   0.00286   0.00567       700

    accuracy                        0.77563     21745
   macro avg    0.76644   0.67081   0.67608     21745
weighted avg    0.79171   0.77563   0.76505     21745

Accuracy on test data: 0.6546705961227417
Loss on test data: 1.0383383851717807              precision    recall  f1-score   support

           0    0.95703   0.96426   0.96063      1455
           1    0.49330   0.65223   0.56174      1524
           2    0.64425   0.59244   0.61726      1455
           3    0.77970   0.74115   0.75994      5057
           4    0.67742   0.40127   0.50400       157
           5    0.41804   0.28949   0.34209      1665
           6    0.68026   0.26293   0.37926      1586
           7    0.79067   0.94021   0.85898      3696
           8    0.44337   0.85982   0.58505      1120
           9    0.28455   0.08294   0.12844       422
          10    0.64433   0.21186   0.31888       590
          11    0.27505   0.41160   0.32975       707
          12    0.33033   0.53032   0.40709      1105
          13    0.11650   0.02941   0.04697       408
          14    0.21191   0.14898   0.17496      1027
          15    0.08287   0.03676   0.05093       408
          16    0.38267   0.39750   0.38995      1522
          17    0.99753   0.96476   0.98087      5023
          18    0.99631   0.98398   0.99011      1373
          19    0.79037   0.79840   0.79436      3740
          20    0.18750   0.04839   0.07692        62
          21    0.45333   0.26204   0.33211       519
          22    0.00000   0.00000   0.00000        24
          23    0.52619   0.42410   0.46966      2108
          24    0.94271   0.83750   0.88700      1120
          25    0.00000   0.00000   0.00000        62
          26    0.75307   0.67993   0.71463      1081
          27    0.31880   0.98918   0.48219       924
          28    0.56360   0.71713   0.63116      2107
          29    0.11778   0.26471   0.16302       408
          30    0.97532   0.95052   0.96276      1455
          31    0.06612   0.03922   0.04923       408
          32    0.16667   0.00126   0.00250      1586

    accuracy                        0.65467     45904
   macro avg    0.48690   0.47013   0.45310     45904
weighted avg    0.65500   0.65467   0.63765     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_001.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 99
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    0.33333   0.17500   0.22951        40
           1    0.42424   0.30435   0.35443        46
           2    0.41667   0.12500   0.19231        40
           3    0.36486   0.18493   0.24545       146
           4    0.00000   0.00000   0.00000         3
           5    0.02083   0.13158   0.03597        38
           6    0.00000   0.00000   0.00000        39
           7    0.92308   0.10435   0.18750       115
           8    0.00000   0.00000   0.00000        34
           9    1.00000   0.05556   0.10526        18
          10    0.75000   0.11538   0.20000        26
          11    1.00000   0.12500   0.22222        16
          12    0.00000   0.00000   0.00000        25
          13    0.00000   0.00000   0.00000        11
          14    0.22222   0.46667   0.30108        30
          15    0.46667   0.63636   0.53846        11
          16    0.28866   0.60870   0.39161        46
          17    0.33426   0.83333   0.47714       144
          18    1.00000   0.02703   0.05263        37
          19    0.58824   0.40984   0.48309       122
          20    1.00000   0.16667   0.28571         6
          22    0.00000   0.00000   0.00000        16
          23    1.00000   0.25000   0.40000         4
          24    1.00000   0.06000   0.11321        50
          25    0.00000   0.00000   0.00000        34
          26    1.00000   0.16667   0.28571         6
          27    0.00000   0.00000   0.00000        24
          28    0.25000   0.93750   0.39474        32
          29    1.00000   0.16000   0.27586        50
          30    0.00000   0.00000   0.00000        11
          31    0.70000   0.17500   0.28000        40
          32    0.00000   0.00000   0.00000        11
          33    0.13139   0.46154   0.20455        39

    accuracy                        0.27863      1310
   macro avg    0.43074   0.20244   0.18959      1310
weighted avg    0.45980   0.27863   0.24538      1310

Accuracy on test data: 0.1740153431892395
Loss on test data: 2.7995004622352044              precision    recall  f1-score   support

           0    0.06458   0.04811   0.05514      1455
           1    0.28846   0.10827   0.15744      1524
           2    0.03162   0.00550   0.00937      1455
           3    0.28922   0.18628   0.22661      5057
           4    0.00000   0.00000   0.00000       157
           5    0.00980   0.05465   0.01661      1665
           6    0.16667   0.00126   0.00250      1586
           7    0.72571   0.03436   0.06562      3696
           8    0.00000   0.00000   0.00000      1120
           9    0.32143   0.02133   0.04000       422
          10    0.13580   0.01864   0.03279       590
          11    0.16667   0.00283   0.00556       707
          12    0.00000   0.00000   0.00000      1105
          13    0.00000   0.00000   0.00000       408
          14    0.10818   0.11977   0.11368      1027
          15    0.05275   0.05882   0.05562       408
          16    0.17739   0.28252   0.21794      1522
          17    0.24903   0.71212   0.36901      5023
          18    0.94118   0.01165   0.02302      1373
          19    0.54874   0.22727   0.32142      3740
          20    1.00000   0.01613   0.03175        62
          22    0.00000   0.00000   0.00000       519
          23    0.00000   0.00000   0.00000        24
          24    0.77778   0.01328   0.02612      2108
          25    0.00000   0.00000   0.00000      1120
          26    0.00000   0.00000   0.00000        62
          27    0.00000   0.00000   0.00000      1081
          28    0.16044   0.98918   0.27609       924
          29    0.82308   0.05078   0.09566      2107
          30    0.00000   0.00000   0.00000       408
          31    0.20833   0.01375   0.02579      1455
          32    0.00000   0.00000   0.00000       408
          33    0.10324   0.29697   0.15322      1586

    accuracy                        0.17402     45904
   macro avg    0.22273   0.09920   0.07033     45904
weighted avg    0.31343   0.17402   0.13390     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_005.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 95
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    0.99394   0.98795   0.99094       166
           1    0.94595   0.94595   0.94595       185
           2    0.76289   0.89157   0.82222       166
           3    0.76248   0.97864   0.85714       515
           4    1.00000   0.80000   0.88889        20
           5    0.38503   0.67290   0.48980       214
           6    1.00000   1.00000   1.00000       169
           7    0.95825   1.00000   0.97868       505
           8    0.95172   0.99281   0.97183       139
           9    0.93182   0.56164   0.70085        73
          10    1.00000   0.68367   0.81212        98
          11    0.94444   0.24638   0.39080        69
          12    0.40000   0.03448   0.06349       116
          13    0.88889   0.86957   0.87912        46
          14    0.98947   0.86239   0.92157       109
          15    0.77083   0.80435   0.78723        46
          16    0.90110   0.88649   0.89373       185
          17    0.99404   0.99010   0.99206       505
          18    1.00000   1.00000   1.00000       155
          19    0.84641   0.95841   0.89894       529
          20    1.00000   0.22222   0.36364         9
          22    0.81818   0.69231   0.75000        52
          23    1.00000   0.16667   0.28571         6
          24    0.84651   0.92857   0.88564       196
          25    1.00000   0.82734   0.90551       139
          26    1.00000   0.33333   0.50000         9
          27    0.89412   0.66667   0.76382       114
          28    0.00000   0.00000   0.00000       116
          29    0.88073   0.97959   0.92754       196
          30    0.97368   0.80435   0.88095        46
          31    1.00000   0.98795   0.99394       166
          32    0.76471   0.84783   0.80412        46
          33    0.50735   0.40828   0.45246       169

    accuracy                        0.85419      5274
   macro avg    0.85190   0.72825   0.75148      5274
weighted avg    0.84525   0.85419   0.83678      5274

Accuracy on test data: 0.7565571665763855
Loss on test data: 0.898676124118001              precision    recall  f1-score   support

           0    0.97488   0.96014   0.96745      1455
           1    0.79395   0.84449   0.81844      1524
           2    0.60421   0.78900   0.68435      1455
           3    0.75896   0.97133   0.85211      5057
           4    0.48889   0.14013   0.21782       157
           5    0.28463   0.53934   0.37261      1665
           6    1.00000   0.99685   0.99842      1586
           7    0.93442   0.97917   0.95627      3696
           8    0.94615   0.98839   0.96681      1120
           9    0.32161   0.15166   0.20612       422
          10    0.77291   0.32881   0.46136       590
          11    0.26531   0.03678   0.06460       707
          12    0.22951   0.01267   0.02401      1105
          13    0.45918   0.44118   0.45000       408
          14    0.66157   0.67381   0.66763      1027
          15    0.16400   0.20098   0.18062       408
          16    0.60234   0.67674   0.63738      1522
          17    0.99312   0.97691   0.98495      5023
          18    0.99271   0.99199   0.99235      1373
          19    0.75028   0.91016   0.82252      3740
          20    0.50000   0.03226   0.06061        62
          22    0.31737   0.20424   0.24853       519
          23    0.00000   0.00000   0.00000        24
          24    0.59598   0.66129   0.62694      2108
          25    0.97866   0.81875   0.89159      1120
          26    1.00000   0.08065   0.14925        62
          27    0.85753   0.59019   0.69918      1081
          28    0.00000   0.00000   0.00000       924
          29    0.76815   0.77836   0.77322      2107
          30    0.76923   0.26961   0.39927       408
          31    0.97668   0.94983   0.96307      1455
          32    0.33159   0.31127   0.32111       408
          33    0.43699   0.30391   0.35850      1586

    accuracy                        0.75656     45904
   macro avg    0.62215   0.53366   0.53991     45904
weighted avg    0.73535   0.75656   0.73319     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_01.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 90
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    1.00000   0.97701   0.98837       348
           1    0.99013   0.76010   0.86000       396
           2    0.66667   0.82759   0.73846       348
           3    0.76253   0.92430   0.83566      1004
           4    1.00000   0.44444   0.61538        36
           5    0.52000   0.06388   0.11379       407
           6    1.00000   1.00000   1.00000       356
           7    0.96872   0.99541   0.98188      1089
           8    0.98909   0.99634   0.99270       273
           9    1.00000   0.48322   0.65158       149
          10    1.00000   0.50505   0.67114       198
          11    0.81250   0.16049   0.26804       162
          12    0.36607   0.16532   0.22778       248
          13    0.93750   0.69444   0.79787       108
          14    1.00000   0.64167   0.78173       240
          15    0.81690   0.53704   0.64804       108
          16    0.81499   0.87879   0.84569       396
          17    0.99183   0.99082   0.99132       980
          18    1.00000   1.00000   1.00000       328
          19    0.79697   0.97611   0.87749      1130
          20    1.00000   0.68750   0.81481        16
          22    0.75000   0.48649   0.59016       111
          23    0.50000   0.30000   0.37500        10
          24    0.53242   0.98943   0.69231       473
          25    1.00000   0.78388   0.87885       273
          26    0.68421   0.81250   0.74286        16
          27    0.99200   0.50612   0.67027       245
          28    0.32239   0.99083   0.48649       218
          29    0.93151   0.86258   0.89572       473
          30    0.94624   0.81481   0.87562       108
          31    1.00000   0.97989   0.98984       348
          32    0.83871   0.72222   0.77612       108
          33    0.48400   0.33989   0.39934       356

    accuracy                        0.81617     11059
   macro avg    0.83077   0.70600   0.72952     11059
weighted avg    0.84054   0.81617   0.80164     11059

Accuracy on test data: 0.7670137882232666
Loss on test data: 0.958057659283753              precision    recall  f1-score   support

           0    0.99856   0.95189   0.97467      1455
           1    0.95946   0.69882   0.80866      1524
           2    0.61410   0.83230   0.70674      1455
           3    0.77280   0.89322   0.82866      5057
           4    0.80769   0.26752   0.40191       157
           5    0.27869   0.03063   0.05519      1665
           6    1.00000   0.99874   0.99937      1586
           7    0.96195   0.99188   0.97669      3696
           8    0.98927   0.98750   0.98838      1120
           9    0.37129   0.17773   0.24038       422
          10    0.91189   0.35085   0.50673       590
          11    0.32432   0.03395   0.06146       707
          12    0.30864   0.15837   0.20933      1105
          13    0.54661   0.31618   0.40062       408
          14    0.98636   0.63389   0.77178      1027
          15    0.30116   0.19118   0.23388       408
          16    0.64106   0.71813   0.67741      1522
          17    0.99269   0.97392   0.98322      5023
          18    0.99414   0.98908   0.99160      1373
          19    0.75187   0.96578   0.84551      3740
          20    0.80000   0.32258   0.45977        62
          22    0.40394   0.15800   0.22715       519
          23    0.00000   0.00000   0.00000        24
          24    0.46864   0.97106   0.63218      2108
          25    1.00000   0.81071   0.89546      1120
          26    0.64815   0.56452   0.60345        62
          27    0.97769   0.44588   0.61245      1081
          28    0.31880   0.98918   0.48219       924
          29    0.86505   0.79402   0.82801      2107
          30    0.63636   0.41176   0.50000       408
          31    0.99782   0.94433   0.97034      1455
          32    0.43678   0.27941   0.34081       408
          33    0.44602   0.29697   0.35655      1586

    accuracy                        0.76701     45904
   macro avg    0.68218   0.58030   0.59305     45904
weighted avg    0.77331   0.76701   0.74587     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_02.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 80
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    1.00000   0.99693   0.99846       652
           1    0.99465   0.95876   0.97638       776
           2    0.78277   0.64110   0.70489       652
           3    0.76860   0.95709   0.85255      2051
           4    0.94444   0.44156   0.60177        77
           5    0.91935   0.06917   0.12867       824
           6    1.00000   1.00000   1.00000       700
           7    0.98954   0.98269   0.98610      2022
           8    0.99851   0.99703   0.99777       673
           9    0.76339   0.57191   0.65392       299
          10    0.97738   0.60167   0.74483       359
          11    0.76404   0.21118   0.33090       322
          12    0.38065   0.12661   0.19002       466
          13    0.87634   0.78744   0.82952       207
          14    0.95025   0.83043   0.88631       460
          15    0.71628   0.74396   0.72986       207
          16    0.79363   0.93050   0.85664       777
          17    0.99746   0.98444   0.99090      1992
          18    1.00000   1.00000   1.00000       613
          19    0.79704   0.98082   0.87943      2086
          20    0.76667   0.95833   0.85185        24
          22    0.75556   0.66995   0.71018       203
          23    0.33333   0.21429   0.26087        14
          24    0.90134   0.95430   0.92706       919
          25    0.99628   0.79643   0.88522       673
          26    0.76667   0.95833   0.85185        24
          27    0.72835   0.80786   0.76605       458
          28    0.39432   0.99623   0.56501       530
          29    0.97953   0.98912   0.98430       919
          30    0.91758   0.80676   0.85861       207
          31    0.99693   0.99693   0.99693       652
          32    0.79703   0.77778   0.78729       207
          33    0.42057   0.39714   0.40852       700

    accuracy                        0.84806     21745
   macro avg    0.82329   0.76172   0.76341     21745
weighted avg    0.86448   0.84806   0.83137     21745

Accuracy on test data: 0.7960308194160461
Loss on test data: 0.6343298040644638              precision    recall  f1-score   support

           0    0.99653   0.98625   0.99136      1455
           1    0.97445   0.92585   0.94953      1524
           2    0.72106   0.61649   0.66469      1455
           3    0.75796   0.95056   0.84341      5057
           4    0.73529   0.31847   0.44444       157
           5    0.63736   0.03483   0.06606      1665
           6    1.00000   1.00000   1.00000      1586
           7    0.97719   0.98539   0.98127      3696
           8    0.99729   0.98750   0.99237      1120
           9    0.38721   0.27251   0.31989       422
          10    0.88971   0.41017   0.56148       590
          11    0.17160   0.04102   0.06621       707
          12    0.26667   0.06878   0.10935      1105
          13    0.60248   0.47549   0.53151       408
          14    0.79199   0.69328   0.73936      1027
          15    0.33588   0.43137   0.37768       408
          16    0.61789   0.83509   0.71025      1522
          17    0.99711   0.96317   0.97985      5023
          18    1.00000   0.99782   0.99891      1373
          19    0.75779   0.96283   0.84809      3740
          20    0.70370   0.61290   0.65517        62
          22    0.43571   0.23507   0.30538       519
          23    0.00000   0.00000   0.00000        24
          24    0.74630   0.81357   0.77848      2108
          25    0.99028   0.81875   0.89638      1120
          26    0.65517   0.61290   0.63333        62
          27    0.69934   0.77891   0.73698      1081
          28    0.31880   0.98918   0.48219       924
          29    0.95137   0.95634   0.95385      2107
          30    0.68862   0.56373   0.61995       408
          31    0.99722   0.98625   0.99171      1455
          32    0.49153   0.42647   0.45669       408
          33    0.44252   0.30580   0.36167      1586

    accuracy                        0.79603     45904
   macro avg    0.68897   0.63808   0.63780     45904
weighted avg    0.79399   0.79603   0.77395     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_04.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 60
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    0.99921   0.99842   0.99882      1269
           1    0.99696   0.99395   0.99545      1652
           2    0.70253   0.85422   0.77098      1269
           3    0.79514   0.94191   0.86232      4166
           4    0.81731   0.57047   0.67194       149
           5    0.59060   0.10359   0.17626      1699
           6    1.00000   1.00000   1.00000      1359
           7    0.96949   0.99943   0.98423      3529
           8    0.99925   1.00000   0.99962      1325
           9    0.60904   0.57944   0.59387       535
          10    0.95813   0.57459   0.71837       677
          11    0.40777   0.58243   0.47970       649
          12    0.50000   0.23549   0.32018       896
          13    0.94984   0.70302   0.80800       431
          14    0.92814   0.80380   0.86150       948
          15    0.68750   0.76744   0.72527       430
          16    0.77783   0.92926   0.84683      1654
          17    0.98823   0.99433   0.99127      4054
          18    1.00000   0.99915   0.99957      1176
          19    0.84390   0.80886   0.82601      3636
          20    0.94118   0.92308   0.93204        52
          22    0.75229   0.53132   0.62278       463
          23    1.00000   0.19355   0.32432        31
          24    0.87888   0.93486   0.90601      2057
          25    0.95053   0.81208   0.87586      1325
          26    1.00000   1.00000   1.00000        52
          27    0.98830   0.57811   0.72950       877
          28    0.38278   0.99709   0.55319      1030
          29    0.96338   0.99757   0.98018      2057
          30    0.85885   0.83295   0.84570       431
          31    0.99529   0.99921   0.99725      1269
          32    0.81356   0.77958   0.79621       431
          33    0.40755   0.30979   0.35201      1359

    accuracy                        0.84023     42937
   macro avg    0.83192   0.76754   0.77410     42937
weighted avg    0.84975   0.84023   0.82951     42937

Accuracy on test data: 0.8050279021263123
Loss on test data: 0.5319161100196855              precision    recall  f1-score   support

           0    0.99931   0.99450   0.99690      1455
           1    0.98748   0.98360   0.98554      1524
           2    0.67163   0.83643   0.74503      1455
           3    0.78200   0.92782   0.84869      5057
           4    0.71429   0.44586   0.54902       157
           5    0.51739   0.07147   0.12559      1665
           6    1.00000   0.99937   0.99968      1586
           7    0.97518   0.99946   0.98717      3696
           8    0.98496   0.99375   0.98933      1120
           9    0.34986   0.30095   0.32357       422
          10    0.87162   0.43729   0.58239       590
          11    0.28485   0.40170   0.33333       707
          12    0.45082   0.19910   0.27621      1105
          13    0.71784   0.42402   0.53313       408
          14    0.83771   0.71373   0.77077      1027
          15    0.40286   0.48284   0.43924       408
          16    0.65012   0.86925   0.74389      1522
          17    0.99636   0.98069   0.98846      5023
          18    1.00000   1.00000   1.00000      1373
          19    0.80657   0.79492   0.80070      3740
          20    0.85714   0.58065   0.69231        62
          22    0.54852   0.25048   0.34392       519
          23    0.50000   0.08333   0.14286        24
          24    0.79453   0.88235   0.83614      2108
          25    0.96701   0.83750   0.89761      1120
          26    0.97778   0.70968   0.82243        62
          27    0.95506   0.55042   0.69836      1081
          28    0.31839   0.99134   0.48198       924
          29    0.94012   0.99098   0.96488      2107
          30    0.60881   0.57598   0.59194       408
          31    0.98911   0.99863   0.99384      1455
          32    0.58065   0.52941   0.55385       408
          33    0.45385   0.26356   0.33347      1586

    accuracy                        0.80503     45904
   macro avg    0.74218   0.66973   0.67795     45904
weighted avg    0.81345   0.80503   0.79207     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_06.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 40
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    1.00000   0.99879   0.99939      1647
           1    0.98551   0.99858   0.99200      2111
           2    0.72187   0.82574   0.77032      1647
           3    0.74621   0.98384   0.84871      5260
           4    0.48162   0.64216   0.55042       204
           5    0.50212   0.30624   0.38045      2707
           6    1.00000   1.00000   1.00000      1858
           7    0.97324   0.99913   0.98602      4587
           8    0.99946   1.00000   0.99973      1844
           9    0.76520   0.51192   0.61345       713
          10    0.98113   0.55254   0.70695       847
          11    0.55220   0.23318   0.32790       862
          12    0.55556   0.01246   0.02437      1204
          13    0.93427   0.68151   0.78812       584
          14    0.82258   0.86371   0.84264      1240
          15    0.68561   0.66209   0.67365       583
          16    0.79373   0.87411   0.83198      2113
          17    0.99273   0.98595   0.98933      5124
          18    0.99935   0.99935   0.99935      1541
          19    0.78624   0.95249   0.86142      4715
          20    0.84615   0.91667   0.88000        84
          21    1.00000   1.00000   1.00000         3
          22    0.56866   0.61863   0.59259       569
          23    0.60000   0.21429   0.31579        42
          24    0.91038   0.86770   0.88853      2517
          25    0.87188   0.87046   0.87117      1845
          26    1.00000   0.96429   0.98182        84
          27    0.95816   0.60632   0.74268      1171
          28    0.36807   0.99663   0.53760      1485
          29    0.99325   0.99404   0.99365      2517
          30    0.81865   0.81164   0.81513       584
          31    0.99879   0.99879   0.99879      1647
          32    0.77123   0.76199   0.76658       584
          33    0.75000   0.00161   0.00322      1858

    accuracy                        0.83251     56381
   macro avg    0.81570   0.75608   0.75217     56381
weighted avg    0.84256   0.83251   0.80899     56381

Accuracy on test data: 0.806509256362915
Loss on test data: 0.525071997433101              precision    recall  f1-score   support

           0    1.00000   0.99450   0.99724      1455
           1    0.97550   0.99278   0.98407      1524
           2    0.69000   0.80619   0.74358      1455
           3    0.75638   0.97251   0.85094      5057
           4    0.40206   0.49682   0.44444       157
           5    0.40459   0.26486   0.32015      1665
           6    1.00000   0.99937   0.99968      1586
           7    0.98323   0.99919   0.99114      3696
           8    0.98670   0.99375   0.99021      1120
           9    0.43403   0.29621   0.35211       422
          10    0.90972   0.44407   0.59681       590
          11    0.27458   0.11457   0.16168       707
          12    0.04348   0.00090   0.00177      1105
          13    0.73200   0.44853   0.55623       408
          14    0.71505   0.77702   0.74475      1027
          15    0.38652   0.42157   0.40328       408
          16    0.68182   0.79829   0.73547      1522
          17    0.99673   0.96994   0.98315      5023
          18    1.00000   1.00000   1.00000      1373
          19    0.77130   0.94144   0.84792      3740
          20    0.75000   0.62903   0.68421        62
          22    0.42308   0.33911   0.37647       519
          23    0.12500   0.08333   0.10000        24
          24    0.81241   0.78273   0.79729      2108
          25    0.87175   0.86786   0.86980      1120
          26    0.98039   0.80645   0.88496        62
          27    0.91399   0.58002   0.70968      1081
          28    0.31893   0.99026   0.48247       924
          29    0.98208   0.98813   0.98510      2107
          30    0.61737   0.64461   0.63070       408
          31    0.99656   0.99519   0.99587      1455
          32    0.58105   0.57108   0.57602       408
          33    0.50000   0.00063   0.00126      1586

    accuracy                        0.80651     45904
   macro avg    0.69746   0.66700   0.66056     45904
weighted avg    0.79274   0.80651   0.78106     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_08.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 20
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    1.00000   0.99947   0.99974      1902
           1    0.99832   0.99330   0.99580      2387
           2    0.83180   0.56940   0.67603      1902
           3    0.80423   0.88473   0.84256      6194
           4    0.95833   0.48523   0.64426       237
           5    0.52182   0.34857   0.41795      3807
           6    1.00000   1.00000   1.00000      2202
           7    0.97690   0.99885   0.98775      5207
           8    0.99916   1.00000   0.99958      2387
           9    0.88078   0.42638   0.57460       849
          10    0.94536   0.59049   0.72693       967
          11    0.38815   0.43595   0.41066      1007
          12    0.40981   0.40542   0.40761      1401
          13    0.87238   0.72741   0.79332       686
          14    0.94369   0.77942   0.85372      1419
          15    0.79032   0.50073   0.61305       685
          16    0.75510   0.91377   0.82689      2389
          17    0.98766   0.99453   0.99109      6038
          18    1.00000   0.99944   0.99972      1785
          19    0.80092   0.87689   0.83719      5345
          20    0.86923   0.94167   0.90400       120
          21    1.00000   1.00000   1.00000         3
          22    0.54493   0.59777   0.57013       629
          23    1.00000   0.12069   0.21538        58
          24    0.85604   0.95132   0.90117      2794
          25    0.99194   0.82496   0.90078      2388
          26    1.00000   0.98333   0.99160       120
          27    0.67733   0.88490   0.76732      1364
          28    0.36163   0.99743   0.53081      1943
          29    0.99136   0.98533   0.98833      2794
          30    0.72460   0.86297   0.78776       686
          31    0.99842   0.99947   0.99895      1902
          32    0.82946   0.62391   0.71215       686
          33    0.75000   0.00136   0.00272      2202

    accuracy                        0.82246     66485
   macro avg    0.83705   0.75603   0.76087     66485
weighted avg    0.84345   0.82246   0.81030     66485

Accuracy on test data: 0.8062695860862732
Loss on test data: 0.5011868333647209              precision    recall  f1-score   support

           0    0.99862   0.99725   0.99794      1455
           1    0.99201   0.97703   0.98446      1524
           2    0.77799   0.55395   0.64713      1455
           3    0.79946   0.88531   0.84020      5057
           4    0.97059   0.42038   0.58667       157
           5    0.40597   0.30210   0.34642      1665
           6    1.00000   1.00000   1.00000      1586
           7    0.98398   0.99702   0.99046      3696
           8    0.99463   0.99286   0.99374      1120
           9    0.56316   0.25355   0.34967       422
          10    0.86164   0.46441   0.60352       590
          11    0.26181   0.27440   0.26796       707
          12    0.36617   0.30950   0.33546      1105
          13    0.62914   0.46569   0.53521       408
          14    0.91217   0.70789   0.79715      1027
          15    0.58974   0.33824   0.42991       408
          16    0.65287   0.88108   0.75000      1522
          17    0.99599   0.98825   0.99211      5023
          18    1.00000   0.99927   0.99964      1373
          19    0.78595   0.87674   0.82887      3740
          20    0.75862   0.70968   0.73333        62
          22    0.48361   0.34104   0.40000       519
          23    0.50000   0.08333   0.14286        24
          24    0.79088   0.91319   0.84764      2108
          25    0.98933   0.82768   0.90131      1120
          26    1.00000   0.85484   0.92174        62
          27    0.66447   0.84089   0.74234      1081
          28    0.31870   0.99026   0.48221       924
          29    0.98658   0.97722   0.98188      2107
          30    0.53711   0.67402   0.59783       408
          31    0.99793   0.99588   0.99690      1455
          32    0.54259   0.42157   0.47448       408
          33    1.00000   0.00063   0.00126      1586

    accuracy                        0.80627     45904
   macro avg    0.76096   0.67622   0.68183     45904
weighted avg    0.83001   0.80627   0.79213     45904

------------------------------------------
Training File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_train_red_10.csv
 Training-Test-Ratio: 03
 Splitter: Time
 Reducer: Time
 Reduction Factor: 0
 Test File: I:\Lab\Real_Life_Event_Logs\BPI_Challenge_2012\data\SplitterByStartingTime\0.3\ReducerByTime\Pasquadibisceglie\inp_log_test.csv
              precision    recall  f1-score   support

           0    1.00000   0.99722   0.99861      2159
           1    0.99576   0.99193   0.99384      2602
           2    0.75115   0.75776   0.75444      2159
           3    0.80291   0.87817   0.83886      6977
           4    1.00000   0.45522   0.62564       268
           5    0.43298   0.86924   0.57804      4902
           6    1.00000   1.00000   1.00000      2593
           7    0.98216   0.99370   0.98789      5872
           8    0.99966   0.99897   0.99931      2904
           9    0.83152   0.45717   0.58997      1004
          10    0.87270   0.60181   0.71237      1105
          11    0.60282   0.18988   0.28880      1127
          12    0.41847   0.43408   0.42613      1608
          13    0.90642   0.63824   0.74905       774
          14    0.77480   0.88875   0.82787      1564
          15    0.48426   0.67746   0.56479       772
          16    0.79314   0.86104   0.82569      2605
          17    0.98875   0.99471   0.99172      6806
          18    1.00000   0.99951   0.99975      2032
          19    0.77794   0.95504   0.85744      6027
          20    0.88750   0.91026   0.89873       156
          21    1.00000   1.00000   1.00000         3
          22    0.58824   0.52553   0.55511       666
          23    0.58824   0.14085   0.22727        71
          24    0.89094   0.85175   0.87090      2887
          25    0.99260   0.83064   0.90442      2905
          26    1.00000   0.98718   0.99355       156
          27    0.83675   0.70415   0.76475      1565
          28    1.00000   0.00210   0.00418      2385
          29    0.98626   0.99446   0.99034      2887
          30    0.74402   0.80362   0.77267       774
          31    0.99815   0.99861   0.99838      2159
          32    0.80208   0.69638   0.74550       774
          33    0.83333   0.00193   0.00385      2593

    accuracy                        0.82123     75841
   macro avg    0.84010   0.73786   0.74529     75841
weighted avg    0.85473   0.82123   0.79843     75841

Accuracy on test data: 0.8053982257843018
Loss on test data: 0.5054064517384333              precision    recall  f1-score   support

           0    1.00000   0.99519   0.99759      1455
           1    0.99141   0.98491   0.98815      1524
           2    0.72077   0.72027   0.72052      1455
           3    0.80199   0.87779   0.83818      5057
           4    0.95714   0.42675   0.59031       157
           5    0.32536   0.80841   0.46398      1665
           6    1.00000   1.00000   1.00000      1586
           7    0.99001   0.99215   0.99108      3696
           8    0.99730   0.99107   0.99418      1120
           9    0.49402   0.29384   0.36850       422
          10    0.75556   0.46102   0.57263       590
          11    0.34536   0.09477   0.14872       707
          12    0.38151   0.32489   0.35093      1105
          13    0.72541   0.43382   0.54294       408
          14    0.66198   0.77994   0.71614      1027
          15    0.32278   0.52451   0.39963       408
          16    0.71307   0.82457   0.76478      1522
          17    0.99758   0.98626   0.99189      5023
          18    1.00000   1.00000   1.00000      1373
          19    0.77033   0.94973   0.85068      3740
          20    0.77419   0.77419   0.77419        62
          22    0.45198   0.30829   0.36655       519
          23    0.28571   0.08333   0.12903        24
          24    0.81180   0.78985   0.80067      2108
          25    0.98824   0.82500   0.89927      1120
          26    1.00000   0.95161   0.97521        62
          27    0.79077   0.68178   0.73224      1081
          28    0.25000   0.00108   0.00216       924
          29    0.98534   0.98861   0.98697      2107
          30    0.60345   0.68627   0.64220       408
          31    0.99450   0.99381   0.99416      1455
          32    0.61562   0.50245   0.55331       408
          33    1.00000   0.00063   0.00126      1586

    accuracy                        0.80540     45904
   macro avg    0.74252   0.66839   0.67115     45904
weighted avg    0.82267   0.80540   0.78611     45904

------------------------------------------
